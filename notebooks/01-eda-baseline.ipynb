{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 📊 Credit Risk Prediction - EDA & Baseline Models\n",
        "\n",
        "**Análise Exploratória de Dados e Modelos Baseline**\n",
        "\n",
        "Este notebook demonstra as competências necessárias para o **Bootcamp Microsoft Data Scientist Azure**:\n",
        "\n",
        "- 🔍 **Exploração e preparação de dados**\n",
        "- 📈 **Análise estatística e visualizações**\n",
        "- 🤖 **Baseline modeling e comparação de algoritmos**\n",
        "- 📊 **Avaliação de modelos com múltiplas métricas**\n",
        "- 🎯 **Feature engineering e seleção**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports e configurações\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML imports\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import xgboost as xgb\n",
        "\n",
        "# Configurações de visualização\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"✅ Bibliotecas importadas com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 📥 Carregamento e Preparação dos Dados\n",
        "\n",
        "Nesta seção vamos:\n",
        "- Carregar o dataset de risco de crédito\n",
        "- Realizar análise inicial da estrutura dos dados\n",
        "- Identificar missing values e outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para criar dados sintéticos (para demonstração)\n",
        "def create_synthetic_credit_data(n_samples=1000, random_state=42):\n",
        "    \"\"\"Cria dataset sintético para demonstração do Bootcamp Microsoft Azure\"\"\"\n",
        "    np.random.seed(random_state)\n",
        "    \n",
        "    data = {\n",
        "        'age': np.random.randint(18, 80, n_samples),\n",
        "        'annual_income': np.random.lognormal(10, 1, n_samples),\n",
        "        'loan_amount': np.random.lognormal(9, 1, n_samples),\n",
        "        'credit_score': np.random.randint(300, 850, n_samples),\n",
        "        'employment_length': np.random.randint(0, 25, n_samples),\n",
        "        'debt_to_income': np.random.uniform(0, 1, n_samples),\n",
        "        'num_credit_lines': np.random.randint(1, 20, n_samples),\n",
        "        'education': np.random.choice(['High School', 'College', 'Graduate'], n_samples),\n",
        "        'home_ownership': np.random.choice(['Rent', 'Own', 'Mortgage'], n_samples),\n",
        "    }\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Criar variável target com lógica de negócio realista\n",
        "    risk_score = (\n",
        "        (df['credit_score'] < 600).astype(int) * 0.4 +\n",
        "        (df['debt_to_income'] > 0.5).astype(int) * 0.3 +\n",
        "        (df['annual_income'] < 30000).astype(int) * 0.2 +\n",
        "        np.random.random(n_samples) * 0.1\n",
        "    )\n",
        "    \n",
        "    df['default'] = (risk_score > 0.5).astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Carregar ou criar dados\n",
        "try:\n",
        "    df = pd.read_csv('../data/credit_risk.csv')\n",
        "    print(\"📊 Dataset carregado do arquivo\")\n",
        "except:\n",
        "    print(\"⚠️  Criando dataset sintético para demonstração...\")\n",
        "    df = create_synthetic_credit_data(2000, 42)\n",
        "    # Salvar para uso futuro\n",
        "    import os\n",
        "    os.makedirs('../data', exist_ok=True)\n",
        "    df.to_csv('../data/credit_risk.csv', index=False)\n",
        "    print(\"💾 Dataset sintético salvo em ../data/credit_risk.csv\")\n",
        "\n",
        "print(f\"✅ Dataset carregado: {df.shape[0]} linhas, {df.shape[1]} colunas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Análise inicial dos dados\n",
        "print(\"=\"*50)\n",
        "print(\"📋 RESUMO DO DATASET\")\n",
        "print(\"=\"*50)\n",
        "print(f\"📊 Shape: {df.shape}\")\n",
        "print(f\"🎯 Taxa de Default: {df['default'].mean():.2%}\")\n",
        "print(f\"💰 Renda média: ${df['annual_income'].mean():,.0f}\")\n",
        "print(f\"📈 Score de crédito médio: {df['credit_score'].mean():.0f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"📊 INFORMAÇÕES GERAIS\")\n",
        "print(\"=\"*50)\n",
        "display(df.info())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50) \n",
        "print(\"📈 ESTATÍSTICAS DESCRITIVAS\")\n",
        "print(\"=\"*50)\n",
        "display(df.describe())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🔍 PRIMEIRAS 5 LINHAS\")\n",
        "print(\"=\"*50)\n",
        "display(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 📊 Análise Exploratória de Dados (EDA)\n",
        "\n",
        "Análise detalhada das variáveis e suas relações com o target (default).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizações da distribuição do target\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Distribuição do target\n",
        "df['default'].value_counts().plot(kind='bar', ax=axes[0], color=['lightgreen', 'salmon'])\n",
        "axes[0].set_title('📊 Distribuição da Variável Target')\n",
        "axes[0].set_xlabel('Default (0=Não, 1=Sim)')\n",
        "axes[0].set_ylabel('Frequência')\n",
        "axes[0].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# Adicionar percentuais nas barras\n",
        "for i, v in enumerate(df['default'].value_counts()):\n",
        "    pct = v / len(df) * 100\n",
        "    axes[0].text(i, v + 50, f'{v}\\n({pct:.1f}%)', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Taxa de default por faixa de credit score\n",
        "credit_bins = pd.cut(df['credit_score'], bins=5, labels=['Muito Baixo', 'Baixo', 'Médio', 'Alto', 'Muito Alto'])\n",
        "default_rate = df.groupby(credit_bins)['default'].mean()\n",
        "default_rate.plot(kind='bar', ax=axes[1], color='skyblue')\n",
        "axes[1].set_title('📈 Taxa de Default por Faixa de Credit Score')\n",
        "axes[1].set_xlabel('Faixa de Credit Score')\n",
        "axes[1].set_ylabel('Taxa de Default')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for i, v in enumerate(default_rate):\n",
        "    axes[1].text(i, v + 0.01, f'{v:.2%}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"🎯 Insights iniciais:\")\n",
        "print(f\"   • Dataset está {'balanceado' if 0.4 <= df['default'].mean() <= 0.6 else 'desbalanceado'}\")\n",
        "print(f\"   • Taxa geral de default: {df['default'].mean():.2%}\")\n",
        "print(f\"   • Credit Score médio dos que fizeram default: {df[df['default']==1]['credit_score'].mean():.0f}\")\n",
        "print(f\"   • Credit Score médio dos que NÃO fizeram default: {df[df['default']==0]['credit_score'].mean():.0f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 🤖 Baseline Models & Comparação\n",
        "\n",
        "Implementação e comparação de múltiplos algoritmos - competência essencial do Bootcamp Microsoft Azure:\n",
        "\n",
        "- **Logistic Regression** (baseline linear)\n",
        "- **Random Forest** (ensemble method)\n",
        "- **XGBoost** (gradient boosting)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparação dos dados para modelagem\n",
        "def prepare_data_for_modeling(df):\n",
        "    \"\"\"Preprocessa dados seguindo boas práticas do Bootcamp Microsoft Azure\"\"\"\n",
        "    \n",
        "    df_processed = df.copy()\n",
        "    \n",
        "    # 1. Separar features e target\n",
        "    X = df_processed.drop('default', axis=1)\n",
        "    y = df_processed['default']\n",
        "    \n",
        "    # 2. Encoding de variáveis categóricas\n",
        "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "    \n",
        "    for col in categorical_cols:\n",
        "        # One-hot encoding para poucas categorias\n",
        "        if X[col].nunique() <= 5:\n",
        "            dummies = pd.get_dummies(X[col], prefix=col, drop_first=True)\n",
        "            X = pd.concat([X.drop(col, axis=1), dummies], axis=1)\n",
        "        else:\n",
        "            # Label encoding para muitas categorias\n",
        "            le = LabelEncoder()\n",
        "            X[col] = le.fit_transform(X[col])\n",
        "    \n",
        "    # 3. Feature Engineering \n",
        "    # Loan to Income Ratio\n",
        "    X['loan_to_income_ratio'] = X['loan_amount'] / (X['annual_income'] + 1)\n",
        "    \n",
        "    # Credit Score normalizado\n",
        "    X['credit_score_norm'] = (X['credit_score'] - 300) / (850 - 300)\n",
        "    \n",
        "    # Indicador de alto risco\n",
        "    X['high_risk_profile'] = ((X['debt_to_income'] > 0.5) & (X['credit_score'] < 600)).astype(int)\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "# Preparar dados\n",
        "print(\"🔄 Preparando dados para modelagem...\")\n",
        "X, y = prepare_data_for_modeling(df)\n",
        "\n",
        "print(f\"✅ Preparação concluída:\")\n",
        "print(f\"   • Features: {X.shape[1]}\")\n",
        "print(f\"   • Samples: {X.shape[0]}\")\n",
        "print(f\"   • Target distribution: {y.value_counts().to_dict()}\")\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\n📊 Split realizado:\")\n",
        "print(f\"   • Treino: {X_train.shape[0]} samples\")\n",
        "print(f\"   • Teste: {X_test.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treinamento e comparação de múltiplos modelos\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Definir modelos para comparação\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "# Treinar e avaliar cada modelo\n",
        "results = []\n",
        "\n",
        "print(\"🏋️  Treinando modelos...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n🤖 Treinando {name}...\")\n",
        "    \n",
        "    # Treinamento\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Predições\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Métricas\n",
        "    metrics = {\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1-Score': f1_score(y_test, y_pred),\n",
        "        'AUC': roc_auc_score(y_test, y_pred_proba)\n",
        "    }\n",
        "    \n",
        "    results.append(metrics)\n",
        "    \n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "    \n",
        "    print(f\"   ✅ Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "    print(f\"   📈 AUC: {metrics['AUC']:.4f}\")\n",
        "    print(f\"   🔄 CV AUC: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
        "\n",
        "# Criar DataFrame com resultados\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.round(4)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 COMPARAÇÃO DE MODELOS\")\n",
        "print(\"=\"*60)\n",
        "display(results_df.set_index('Model').sort_values('AUC', ascending=False))\n",
        "\n",
        "# Melhor modelo\n",
        "best_model_name = results_df.loc[results_df['AUC'].idxmax(), 'Model']\n",
        "best_auc = results_df['AUC'].max()\n",
        "\n",
        "print(f\"\\n🏆 MELHOR MODELO: {best_model_name}\")\n",
        "print(f\"🎯 AUC Score: {best_auc:.4f}\")\n",
        "\n",
        "# Salvar melhor modelo para uso posterior\n",
        "best_model = models[best_model_name]\n",
        "import joblib\n",
        "import os\n",
        "os.makedirs('../outputs', exist_ok=True)\n",
        "joblib.dump(best_model, f'../outputs/{best_model_name.lower().replace(\" \", \"_\")}_model.pkl')\n",
        "print(f\"💾 Modelo salvo: ../outputs/{best_model_name.lower().replace(' ', '_')}_model.pkl\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
