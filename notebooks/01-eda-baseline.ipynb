{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“Š Credit Risk Prediction - EDA & Baseline Models\n",
        "\n",
        "**AnÃ¡lise ExploratÃ³ria de Dados e Modelos Baseline**\n",
        "\n",
        "Este notebook demonstra as competÃªncias necessÃ¡rias para o **Bootcamp Microsoft Data Scientist Azure**:\n",
        "\n",
        "- ğŸ” **ExploraÃ§Ã£o e preparaÃ§Ã£o de dados**\n",
        "- ğŸ“ˆ **AnÃ¡lise estatÃ­stica e visualizaÃ§Ãµes**\n",
        "- ğŸ¤– **Baseline modeling e comparaÃ§Ã£o de algoritmos**\n",
        "- ğŸ“Š **AvaliaÃ§Ã£o de modelos com mÃºltiplas mÃ©tricas**\n",
        "- ğŸ¯ **Feature engineering e seleÃ§Ã£o**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports e configuraÃ§Ãµes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML imports\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import xgboost as xgb\n",
        "\n",
        "# ConfiguraÃ§Ãµes de visualizaÃ§Ã£o\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"âœ… Bibliotecas importadas com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ğŸ“¥ Carregamento e PreparaÃ§Ã£o dos Dados\n",
        "\n",
        "Nesta seÃ§Ã£o vamos:\n",
        "- Carregar o dataset de risco de crÃ©dito\n",
        "- Realizar anÃ¡lise inicial da estrutura dos dados\n",
        "- Identificar missing values e outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FunÃ§Ã£o para criar dados sintÃ©ticos (para demonstraÃ§Ã£o)\n",
        "def create_synthetic_credit_data(n_samples=1000, random_state=42):\n",
        "    \"\"\"Cria dataset sintÃ©tico para demonstraÃ§Ã£o do Bootcamp Microsoft Azure\"\"\"\n",
        "    np.random.seed(random_state)\n",
        "    \n",
        "    data = {\n",
        "        'age': np.random.randint(18, 80, n_samples),\n",
        "        'annual_income': np.random.lognormal(10, 1, n_samples),\n",
        "        'loan_amount': np.random.lognormal(9, 1, n_samples),\n",
        "        'credit_score': np.random.randint(300, 850, n_samples),\n",
        "        'employment_length': np.random.randint(0, 25, n_samples),\n",
        "        'debt_to_income': np.random.uniform(0, 1, n_samples),\n",
        "        'num_credit_lines': np.random.randint(1, 20, n_samples),\n",
        "        'education': np.random.choice(['High School', 'College', 'Graduate'], n_samples),\n",
        "        'home_ownership': np.random.choice(['Rent', 'Own', 'Mortgage'], n_samples),\n",
        "    }\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Criar variÃ¡vel target com lÃ³gica de negÃ³cio realista\n",
        "    risk_score = (\n",
        "        (df['credit_score'] < 600).astype(int) * 0.4 +\n",
        "        (df['debt_to_income'] > 0.5).astype(int) * 0.3 +\n",
        "        (df['annual_income'] < 30000).astype(int) * 0.2 +\n",
        "        np.random.random(n_samples) * 0.1\n",
        "    )\n",
        "    \n",
        "    df['default'] = (risk_score > 0.5).astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Carregar ou criar dados\n",
        "try:\n",
        "    df = pd.read_csv('../data/credit_risk.csv')\n",
        "    print(\"ğŸ“Š Dataset carregado do arquivo\")\n",
        "except:\n",
        "    print(\"âš ï¸  Criando dataset sintÃ©tico para demonstraÃ§Ã£o...\")\n",
        "    df = create_synthetic_credit_data(2000, 42)\n",
        "    # Salvar para uso futuro\n",
        "    import os\n",
        "    os.makedirs('../data', exist_ok=True)\n",
        "    df.to_csv('../data/credit_risk.csv', index=False)\n",
        "    print(\"ğŸ’¾ Dataset sintÃ©tico salvo em ../data/credit_risk.csv\")\n",
        "\n",
        "print(f\"âœ… Dataset carregado: {df.shape[0]} linhas, {df.shape[1]} colunas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AnÃ¡lise inicial dos dados\n",
        "print(\"=\"*50)\n",
        "print(\"ğŸ“‹ RESUMO DO DATASET\")\n",
        "print(\"=\"*50)\n",
        "print(f\"ğŸ“Š Shape: {df.shape}\")\n",
        "print(f\"ğŸ¯ Taxa de Default: {df['default'].mean():.2%}\")\n",
        "print(f\"ğŸ’° Renda mÃ©dia: ${df['annual_income'].mean():,.0f}\")\n",
        "print(f\"ğŸ“ˆ Score de crÃ©dito mÃ©dio: {df['credit_score'].mean():.0f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸ“Š INFORMAÃ‡Ã•ES GERAIS\")\n",
        "print(\"=\"*50)\n",
        "display(df.info())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50) \n",
        "print(\"ğŸ“ˆ ESTATÃSTICAS DESCRITIVAS\")\n",
        "print(\"=\"*50)\n",
        "display(df.describe())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸ” PRIMEIRAS 5 LINHAS\")\n",
        "print(\"=\"*50)\n",
        "display(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ğŸ“Š AnÃ¡lise ExploratÃ³ria de Dados (EDA)\n",
        "\n",
        "AnÃ¡lise detalhada das variÃ¡veis e suas relaÃ§Ãµes com o target (default).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VisualizaÃ§Ãµes da distribuiÃ§Ã£o do target\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# DistribuiÃ§Ã£o do target\n",
        "df['default'].value_counts().plot(kind='bar', ax=axes[0], color=['lightgreen', 'salmon'])\n",
        "axes[0].set_title('ğŸ“Š DistribuiÃ§Ã£o da VariÃ¡vel Target')\n",
        "axes[0].set_xlabel('Default (0=NÃ£o, 1=Sim)')\n",
        "axes[0].set_ylabel('FrequÃªncia')\n",
        "axes[0].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# Adicionar percentuais nas barras\n",
        "for i, v in enumerate(df['default'].value_counts()):\n",
        "    pct = v / len(df) * 100\n",
        "    axes[0].text(i, v + 50, f'{v}\\n({pct:.1f}%)', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Taxa de default por faixa de credit score\n",
        "credit_bins = pd.cut(df['credit_score'], bins=5, labels=['Muito Baixo', 'Baixo', 'MÃ©dio', 'Alto', 'Muito Alto'])\n",
        "default_rate = df.groupby(credit_bins)['default'].mean()\n",
        "default_rate.plot(kind='bar', ax=axes[1], color='skyblue')\n",
        "axes[1].set_title('ğŸ“ˆ Taxa de Default por Faixa de Credit Score')\n",
        "axes[1].set_xlabel('Faixa de Credit Score')\n",
        "axes[1].set_ylabel('Taxa de Default')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for i, v in enumerate(default_rate):\n",
        "    axes[1].text(i, v + 0.01, f'{v:.2%}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ğŸ¯ Insights iniciais:\")\n",
        "print(f\"   â€¢ Dataset estÃ¡ {'balanceado' if 0.4 <= df['default'].mean() <= 0.6 else 'desbalanceado'}\")\n",
        "print(f\"   â€¢ Taxa geral de default: {df['default'].mean():.2%}\")\n",
        "print(f\"   â€¢ Credit Score mÃ©dio dos que fizeram default: {df[df['default']==1]['credit_score'].mean():.0f}\")\n",
        "print(f\"   â€¢ Credit Score mÃ©dio dos que NÃƒO fizeram default: {df[df['default']==0]['credit_score'].mean():.0f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ğŸ¤– Baseline Models & ComparaÃ§Ã£o\n",
        "\n",
        "ImplementaÃ§Ã£o e comparaÃ§Ã£o de mÃºltiplos algoritmos - competÃªncia essencial do Bootcamp Microsoft Azure:\n",
        "\n",
        "- **Logistic Regression** (baseline linear)\n",
        "- **Random Forest** (ensemble method)\n",
        "- **XGBoost** (gradient boosting)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PreparaÃ§Ã£o dos dados para modelagem\n",
        "def prepare_data_for_modeling(df):\n",
        "    \"\"\"Preprocessa dados seguindo boas prÃ¡ticas do Bootcamp Microsoft Azure\"\"\"\n",
        "    \n",
        "    df_processed = df.copy()\n",
        "    \n",
        "    # 1. Separar features e target\n",
        "    X = df_processed.drop('default', axis=1)\n",
        "    y = df_processed['default']\n",
        "    \n",
        "    # 2. Encoding de variÃ¡veis categÃ³ricas\n",
        "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "    \n",
        "    for col in categorical_cols:\n",
        "        # One-hot encoding para poucas categorias\n",
        "        if X[col].nunique() <= 5:\n",
        "            dummies = pd.get_dummies(X[col], prefix=col, drop_first=True)\n",
        "            X = pd.concat([X.drop(col, axis=1), dummies], axis=1)\n",
        "        else:\n",
        "            # Label encoding para muitas categorias\n",
        "            le = LabelEncoder()\n",
        "            X[col] = le.fit_transform(X[col])\n",
        "    \n",
        "    # 3. Feature Engineering \n",
        "    # Loan to Income Ratio\n",
        "    X['loan_to_income_ratio'] = X['loan_amount'] / (X['annual_income'] + 1)\n",
        "    \n",
        "    # Credit Score normalizado\n",
        "    X['credit_score_norm'] = (X['credit_score'] - 300) / (850 - 300)\n",
        "    \n",
        "    # Indicador de alto risco\n",
        "    X['high_risk_profile'] = ((X['debt_to_income'] > 0.5) & (X['credit_score'] < 600)).astype(int)\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "# Preparar dados\n",
        "print(\"ğŸ”„ Preparando dados para modelagem...\")\n",
        "X, y = prepare_data_for_modeling(df)\n",
        "\n",
        "print(f\"âœ… PreparaÃ§Ã£o concluÃ­da:\")\n",
        "print(f\"   â€¢ Features: {X.shape[1]}\")\n",
        "print(f\"   â€¢ Samples: {X.shape[0]}\")\n",
        "print(f\"   â€¢ Target distribution: {y.value_counts().to_dict()}\")\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nğŸ“Š Split realizado:\")\n",
        "print(f\"   â€¢ Treino: {X_train.shape[0]} samples\")\n",
        "print(f\"   â€¢ Teste: {X_test.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treinamento e comparaÃ§Ã£o de mÃºltiplos modelos\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Definir modelos para comparaÃ§Ã£o\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "# Treinar e avaliar cada modelo\n",
        "results = []\n",
        "\n",
        "print(\"ğŸ‹ï¸  Treinando modelos...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nğŸ¤– Treinando {name}...\")\n",
        "    \n",
        "    # Treinamento\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # PrediÃ§Ãµes\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # MÃ©tricas\n",
        "    metrics = {\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1-Score': f1_score(y_test, y_pred),\n",
        "        'AUC': roc_auc_score(y_test, y_pred_proba)\n",
        "    }\n",
        "    \n",
        "    results.append(metrics)\n",
        "    \n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "    \n",
        "    print(f\"   âœ… Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "    print(f\"   ğŸ“ˆ AUC: {metrics['AUC']:.4f}\")\n",
        "    print(f\"   ğŸ”„ CV AUC: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
        "\n",
        "# Criar DataFrame com resultados\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.round(4)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“Š COMPARAÃ‡ÃƒO DE MODELOS\")\n",
        "print(\"=\"*60)\n",
        "display(results_df.set_index('Model').sort_values('AUC', ascending=False))\n",
        "\n",
        "# Melhor modelo\n",
        "best_model_name = results_df.loc[results_df['AUC'].idxmax(), 'Model']\n",
        "best_auc = results_df['AUC'].max()\n",
        "\n",
        "print(f\"\\nğŸ† MELHOR MODELO: {best_model_name}\")\n",
        "print(f\"ğŸ¯ AUC Score: {best_auc:.4f}\")\n",
        "\n",
        "# Salvar melhor modelo para uso posterior\n",
        "best_model = models[best_model_name]\n",
        "import joblib\n",
        "import os\n",
        "os.makedirs('../outputs', exist_ok=True)\n",
        "joblib.dump(best_model, f'../outputs/{best_model_name.lower().replace(\" \", \"_\")}_model.pkl')\n",
        "print(f\"ğŸ’¾ Modelo salvo: ../outputs/{best_model_name.lower().replace(' ', '_')}_model.pkl\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
