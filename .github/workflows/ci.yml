name: üöÄ Bootcamp Microsoft Data Scientist CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:  # Permite execu√ß√£o manual

env:
  PYTHON_VERSION: '3.9'
  
jobs:
  # Job 1: Code Quality & Linting
  code-quality:
    name: üîç Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install black flake8 isort
        pip install -r requirements.txt
    
    - name: Code formatting (Black)
      run: black --check src/ tests/
    
    - name: Import sorting (isort)  
      run: isort --check-only src/ tests/
    
    - name: Linting (Flake8)
      run: flake8 src/ tests/ --max-line-length=100 --ignore=E203,W503

  # Job 2: Unit Tests
  unit-tests:
    name: üß™ Unit Tests
    runs-on: ubuntu-latest
    needs: code-quality
    
    strategy:
      matrix:
        python-version: ['3.8', '3.9', '3.10']
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov pytest-xdist
        pip install -r requirements.txt
    
    - name: Run unit tests
      run: |
        pytest tests/test_data_preprocessing.py tests/test_model_training.py -v \
          --cov=src --cov-report=xml --cov-report=term-missing \
          -x --tb=short
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  # Job 3: Integration Tests  
  integration-tests:
    name: üîó Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest
        pip install -r requirements.txt
    
    - name: Run integration tests (fast)
      run: |
        pytest tests/test_integration.py -v \
          -m "not slow" \
          -x --tb=short
    
    - name: Run slow integration tests
      if: github.event_name == 'push' && github.ref == 'refs/heads/main'
      run: |
        pytest tests/test_integration.py -v \
          -m "slow" \
          --timeout=300 \
          -x --tb=short

  # Job 4: Model Training & Validation
  model-training:
    name: ü§ñ Model Training
    runs-on: ubuntu-latest
    needs: unit-tests
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create data directory
      run: mkdir -p data outputs
    
    - name: Train baseline models
      run: |
        python src/train.py --model logistic --output-dir outputs/logistic
        python src/train.py --model random_forest --output-dir outputs/rf
    
    - name: Validate model performance
      run: |
        python -c "
        import json
        import sys
        
        # Load metrics for both models
        with open('outputs/logistic/metrics.json', 'r') as f:
            logistic_metrics = json.load(f)
        with open('outputs/rf/metrics.json', 'r') as f:
            rf_metrics = json.load(f)
        
        # Minimum performance thresholds
        min_accuracy = 0.6
        min_auc = 0.6
        
        # Check performance
        for model_name, metrics in [('Logistic', logistic_metrics), ('RandomForest', rf_metrics)]:
            accuracy = metrics.get('accuracy', 0)
            auc = metrics.get('auc', 0)
            
            print(f'{model_name}: Accuracy={accuracy:.3f}, AUC={auc:.3f}')
            
            if accuracy < min_accuracy:
                print(f'‚ùå {model_name} accuracy {accuracy:.3f} below threshold {min_accuracy}')
                sys.exit(1)
            
            if auc < min_auc:
                print(f'‚ùå {model_name} AUC {auc:.3f} below threshold {min_auc}')
                sys.exit(1)
        
        print('‚úÖ All models passed performance validation!')
        "
    
    - name: Upload model artifacts
      uses: actions/upload-artifact@v3
      with:
        name: trained-models
        path: outputs/
        retention-days: 30

  # Job 5: Security Scan
  security:
    name: üîí Security Scan
    runs-on: ubuntu-latest
    needs: code-quality
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install safety bandit
        pip install -r requirements.txt
    
    - name: Safety check (known vulnerabilities)
      run: safety check --json
      continue-on-error: true
    
    - name: Bandit security scan
      run: bandit -r src/ -f json
      continue-on-error: true

  # Job 6: Docker Build (opcional)
  docker-build:
    name: üê≥ Docker Build
    runs-on: ubuntu-latest
    needs: integration-tests
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Create Dockerfile
      run: |
        cat > Dockerfile << 'EOF'
        FROM python:3.9-slim
        
        WORKDIR /app
        
        COPY requirements.txt .
        RUN pip install --no-cache-dir -r requirements.txt
        
        COPY src/ ./src/
        COPY azure-ml/ ./azure-ml/
        
        EXPOSE 5000
        
        CMD ["python", "src/predict.py", "--help"]
        EOF
    
    - name: Build Docker image
      run: |
        docker build -t bootcamp-azure-credit-risk:latest .
        docker images
    
    - name: Test Docker image
      run: |
        docker run --rm bootcamp-azure-credit-risk:latest

  # Job 7: Performance Benchmarks
  benchmark:
    name: ‚ö° Performance Benchmark
    runs-on: ubuntu-latest
    needs: model-training
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest-benchmark
        pip install -r requirements.txt
    
    - name: Download model artifacts
      uses: actions/download-artifact@v3
      with:
        name: trained-models
        path: outputs/
    
    - name: Run benchmarks
      run: |
        python -c "
        import time
        import pandas as pd
        import joblib
        import numpy as np
        from src.utils.data_preprocessing import prepare_features
        
        print('üèãÔ∏è Performance Benchmark')
        print('=' * 50)
        
        # Create test data
        np.random.seed(42)
        test_data = pd.DataFrame({
            'age': np.random.randint(18, 80, 1000),
            'annual_income': np.random.lognormal(10, 1, 1000),
            'credit_score': np.random.randint(300, 850, 1000),
            'loan_amount': np.random.lognormal(9, 1, 1000),
            'employment_length': np.random.randint(0, 25, 1000),
            'debt_to_income': np.random.uniform(0, 1, 1000),
            'num_credit_lines': np.random.randint(1, 20, 1000),
            'education': np.random.choice(['High School', 'College', 'Graduate'], 1000),
            'home_ownership': np.random.choice(['Rent', 'Own', 'Mortgage'], 1000),
            'default': np.random.choice([0, 1], 1000)
        })
        
        # Benchmark preprocessing
        start = time.time()
        X, y = prepare_features(test_data)
        preprocess_time = time.time() - start
        print(f'Preprocessing: {preprocess_time:.3f}s for {len(test_data)} samples')
        print(f'Throughput: {len(test_data)/preprocess_time:.0f} samples/sec')
        
        # Benchmark prediction
        model = joblib.load('outputs/rf/random_forest_model.pkl')
        
        start = time.time()
        predictions = model.predict(X)
        predict_time = time.time() - start
        print(f'Prediction: {predict_time:.3f}s for {len(X)} samples')
        print(f'Throughput: {len(X)/predict_time:.0f} predictions/sec')
        
        # Performance thresholds
        if preprocess_time > 5.0:
            print('‚ö†Ô∏è Preprocessing slower than expected')
        if predict_time > 1.0:
            print('‚ö†Ô∏è Prediction slower than expected')
        
        print('‚úÖ Benchmark completed')
        "

  # Job 8: Documentation Update
  update-docs:
    name: üìö Update Documentation
    runs-on: ubuntu-latest
    needs: [model-training, benchmark]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Download model artifacts
      uses: actions/download-artifact@v3
      with:
        name: trained-models
        path: outputs/
    
    - name: Update README with latest results
      run: |
        python -c "
        import json
        import datetime
        
        # Load latest metrics
        with open('outputs/rf/metrics.json', 'r') as f:
            rf_metrics = json.load(f)
        with open('outputs/logistic/metrics.json', 'r') as f:
            lr_metrics = json.load(f)
        
        # Update README with latest results
        results_section = f'''
        ## üìä Latest Results (Updated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')})
        
        | Model | Accuracy | AUC | F1-Score |
        |-------|----------|-----|----------|
        | Random Forest | {rf_metrics.get('accuracy', 0):.3f} | {rf_metrics.get('auc', 0):.3f} | {rf_metrics.get('f1_score', 0):.3f} |
        | Logistic Regression | {lr_metrics.get('accuracy', 0):.3f} | {lr_metrics.get('auc', 0):.3f} | {lr_metrics.get('f1_score', 0):.3f} |
        '''
        
        print('üìä Results updated in documentation')
        "
    
    - name: Commit documentation updates
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add -A
        git diff --staged --quiet || git commit -m "üìä Update model results [skip ci]"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Job 9: Deployment Preparation
  deploy-prep:
    name: üöÄ Deployment Preparation
    runs-on: ubuntu-latest
    needs: [integration-tests, model-training]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Download model artifacts
      uses: actions/download-artifact@v3
      with:
        name: trained-models
        path: outputs/
    
    - name: Prepare deployment package
      run: |
        mkdir -p deployment-package
        
        # Copy necessary files for deployment
        cp -r src/ deployment-package/
        cp -r azure-ml/ deployment-package/
        cp requirements.txt deployment-package/
        cp outputs/rf/random_forest_model.pkl deployment-package/model.pkl
        
        # Create deployment info
        cat > deployment-package/deployment-info.json << EOF
        {
          "model_type": "random_forest",
          "deployment_date": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "git_commit": "${{ github.sha }}",
          "git_ref": "${{ github.ref }}"
        }
        EOF
    
    - name: Upload deployment package
      uses: actions/upload-artifact@v3
      with:
        name: deployment-package
        path: deployment-package/
        retention-days: 30

# Configura√ß√µes globais do workflow
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true
